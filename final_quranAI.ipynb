{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5af5e0f0-8ff0-4c72-a28f-971e6a27c1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding 474 total docs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c0eddceed24335833b82acafc86730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import faiss\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# === Paths ===\n",
    "emotion_dir = \"emotions\"\n",
    "ibadah_dir = \"ibadah\"\n",
    "\n",
    "docs = []\n",
    "metadata = []\n",
    "\n",
    "# === Handle Emotions ===\n",
    "for filename in os.listdir(emotion_dir):\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(os.path.join(emotion_dir, filename), \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            emotion = data.get(\"emotion\", \"unknown\")\n",
    "\n",
    "            for item in data.get(\"ayahs\", {}).get(\"primary\", []):\n",
    "                docs.append(f\"Ayah ({item['reference']}): {item['text_en']}\")\n",
    "                metadata.append({ \"type\": \"ayah\", \"category\": \"emotion\", \"tag\": emotion })\n",
    "\n",
    "            for item in data.get(\"hadiths\", {}).get(\"primary\", []):\n",
    "                docs.append(f\"Hadith: {item['text_en']}\")\n",
    "                metadata.append({ \"type\": \"hadith\", \"category\": \"emotion\", \"tag\": emotion })\n",
    "\n",
    "            for item in data.get(\"duas\", []):\n",
    "                docs.append(f\"Dua: {item['text_en']}\")\n",
    "                metadata.append({ \"type\": \"dua\", \"category\": \"emotion\", \"tag\": emotion })\n",
    "\n",
    "# === Handle Ibadah ===\n",
    "for filename in os.listdir(ibadah_dir):\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(os.path.join(ibadah_dir, filename), \"r\", encoding=\"utf-8\") as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"âš ï¸ Skipping invalid or empty file: {filename}\")\n",
    "                continue\n",
    "\n",
    "            topic = data.get(\"topic\", \"unknown\")\n",
    "\n",
    "            for key, value in data.items():\n",
    "                if isinstance(value, list):\n",
    "                    for item in value:\n",
    "                        if isinstance(item, dict):\n",
    "                            text = item.get(\"text\") or item.get(\"text_en\")\n",
    "                            if text:\n",
    "                                docs.append(f\"{key.capitalize()}: {text}\")\n",
    "                                metadata.append({ \"type\": key, \"category\": \"ibadah\", \"topic\": topic })\n",
    "                        elif isinstance(item, str):\n",
    "                            docs.append(f\"{key.capitalize()}: {item}\")\n",
    "                            metadata.append({ \"type\": key, \"category\": \"ibadah\", \"topic\": topic })\n",
    "\n",
    "                elif isinstance(value, dict):\n",
    "                    for subkey, subvalue in value.items():\n",
    "                        if isinstance(subvalue, list):\n",
    "                            for subitem in subvalue:\n",
    "                                if isinstance(subitem, dict):\n",
    "                                    text = subitem.get(\"text\") or subitem.get(\"text_en\")\n",
    "                                    if text:\n",
    "                                        docs.append(f\"{key.capitalize()} - {subkey}: {text}\")\n",
    "                                        metadata.append({ \"type\": key, \"category\": \"ibadah\", \"topic\": topic })\n",
    "                                elif isinstance(subitem, str):\n",
    "                                    docs.append(f\"{key.capitalize()} - {subkey}: {subitem}\")\n",
    "                                    metadata.append({ \"type\": key, \"category\": \"ibadah\", \"topic\": topic })\n",
    "\n",
    "\n",
    "# === Encode and Index ===\n",
    "print(f\"Encoding {len(docs)} total docs...\")\n",
    "embeddings = model.encode(docs, show_progress_bar=True)\n",
    "\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(np.array(embeddings))\n",
    "\n",
    "# === Save Index + Metadata ===\n",
    "with open(\"fiass_indexer.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"index\": index,\n",
    "        \"metadata\": metadata,\n",
    "        \"docs\": docs\n",
    "    }, f)\n",
    "\n",
    "print(\"Indexing completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90e45ece-3a03-44ef-84c1-f486ff62c877",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize emotion detection classifier\n",
    "classifier = pipeline(\"text-classification\", model=\"nateraw/bert-base-uncased-emotion\")\n",
    "\n",
    "def detect_emotion(text):\n",
    "    \"\"\"\n",
    "    Detect the primary emotion in a text.\n",
    "    Returns a tuple: (label, score)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = classifier(text)[0]\n",
    "        label = result['label']  # e.g., 'sadness'\n",
    "        score = round(result['score'] * 100, 2)  # e.g., 97.2\n",
    "        return label, score\n",
    "    except Exception as e:\n",
    "        return \"unknown\", 0.0, f\"Emotion detection error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "767a148e-4f96-4cb9-9fb3-febd51c0c4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# --- Load FAISS Index ---\n",
    "with open(\"fiass_indexer.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "index = data[\"index\"]\n",
    "metadata = data[\"metadata\"]\n",
    "docs = data[\"docs\"]\n",
    "\n",
    "# --- Embedding Model ---\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# --- LLM Setup (DeepSeek via OpenRouter) ---\n",
    "llm = ChatOpenAI(\n",
    "    model=\"deepseek/deepseek-r1-0528:free\",\n",
    "    openai_api_key=\"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\",\n",
    "    openai_api_base=\"https://openrouter.ai/api/v1\"\n",
    ")\n",
    "\n",
    "# --- Format Retrieved Context ---\n",
    "def format_context(docs, metadata, indices):\n",
    "    context_blocks = []\n",
    "    for idx in indices[0]:\n",
    "        meta = metadata[idx]\n",
    "        text = docs[idx]\n",
    "        block_type = meta.get(\"type\", \"\").lower()\n",
    "\n",
    "        if block_type == \"ayah\":\n",
    "            block = f\"ğŸ“– Ayah ({meta.get('reference', 'unknown')}):\\n{text}\"\n",
    "        elif block_type == \"hadith\":\n",
    "            block = f\"ğŸ—£ Hadith ({meta.get('source', 'unknown')}):\\n{text}\"\n",
    "        elif block_type == \"dua\":\n",
    "            block = f\"ğŸ¤² Dua:\\n{text}\"\n",
    "        else:\n",
    "            block = f\"{text}\"\n",
    "\n",
    "        context_blocks.append(block)\n",
    "    return \"\\n\\n\".join(context_blocks)\n",
    "\n",
    "# --- Classify Query Intent ---\n",
    "def classify_query(user_input: str) -> str:\n",
    "    query = user_input.lower()\n",
    "    if any(w in query for w in [\"sad\", \"depressed\", \"alone\", \"hopeless\", \"anxious\", \"scared\", \"heart\", \"crying\"]):\n",
    "        return \"emotional\"\n",
    "    elif any(w in query for w in [\"how to pray\", \"how to fast\", \"explain wudu\", \"zakat\", \"hajj\", \"umrah\", \"ibadah\", \"tahajjud\"]):\n",
    "        return \"ibadah\"\n",
    "    elif any(w in query for w in [\"fiqh\", \"is it haram\", \"halal\", \"fatwa\", \"allowed in islam\", \"permissible\"]):\n",
    "        return \"fiqh\"\n",
    "    elif any(w in query for w in [\"tafsir\", \"ayah\", \"verse\", \"surah\", \"explain this ayah\", \"what does this mean in quran\"]):\n",
    "        return \"tafsir\"\n",
    "    elif any(w in query for w in [\"prophet\", \"story of\", \"life of\", \"nabi\", \"messenger\", \"who was\"]):\n",
    "        return \"story\"\n",
    "    else:\n",
    "        return \"general\"\n",
    "\n",
    "# --- Main Deen Buddy Function ---\n",
    "def deen_buddy(user_input: str, top_k=6):\n",
    "    try:\n",
    "        query_type = classify_query(user_input)\n",
    "        emotion, confidence = \"sadness\", 0.95  # Replace with actual model if available\n",
    "\n",
    "        # Embed and search FAISS index\n",
    "        query_embedding = embedding_model.encode([user_input])\n",
    "        distances, indices = index.search(np.array(query_embedding), top_k)\n",
    "        formatted_context = format_context(docs, metadata, indices)\n",
    "\n",
    "        # === Prompts ===\n",
    "        if query_type == \"emotional\":\n",
    "            prompt = f\"\"\"\n",
    "You are Deen Buddy, a compassionate and wise Islamic friend.\n",
    "\n",
    "The user is feeling emotionally low (detected: {emotion.upper()}, confidence {confidence:.2f}).\n",
    "\n",
    "Here is some Islamic guidance for your reference:\n",
    "{formatted_context}\n",
    "\n",
    "Now, speak like a close friend â€” warm, heartfelt, and understanding. Comfort them using beautiful reminders from Qur'an and Hadith. Avoid bullet points or headings. Just speak with love and wisdom.\n",
    "\"\"\"\n",
    "\n",
    "        elif query_type == \"ibadah\":\n",
    "            prompt = f\"\"\"\n",
    "The user wants to learn about an Ibadah topic (e.g., prayer, fasting, tahajjud).\n",
    "\n",
    "Use the following authentic Islamic material:\n",
    "{formatted_context}\n",
    "\n",
    "Respond like a friendly teacher helping someone new to the faith. Be warm, simple, and accurate. Include ayahs and hadiths as needed, but do not use bullet points. Just flow like you're having a natural conversation.\n",
    "\"\"\"\n",
    "\n",
    "        elif query_type == \"fiqh\":\n",
    "            return \"This seems like a fiqh-related question. It's best to consult a qualified Mufti or scholar, as fiqh can depend on specific madhabs and contexts. May Allah guide you!\"\n",
    "\n",
    "        elif query_type == \"tafsir\":\n",
    "            prompt = f\"\"\"\n",
    "The user asked for explanation of a Qur'anic ayah or surah.\n",
    "\n",
    "Use the context below if it helps:\n",
    "{formatted_context}\n",
    "\n",
    "Explain the ayah clearly and spiritually, based on authentic tafsir. Include the Arabic and a good English translation. No bullets. Explain gently, with wisdom.\n",
    "\"\"\"\n",
    "\n",
    "        elif query_type == \"story\":\n",
    "            prompt = f\"\"\"\n",
    "The user wants to hear a story from the life of the Prophets or companions.\n",
    "\n",
    "If the context below helps, you may use it:\n",
    "{formatted_context}\n",
    "\n",
    "Narrate the story like a loving friend â€” make it feel real, warm, and spiritually uplifting. Don't list facts. Just flow with emotion and wisdom, using authentic details.\n",
    "\"\"\"\n",
    "\n",
    "        else:  # General\n",
    "            prompt = f\"\"\"\n",
    "User asked: \"{user_input}\"\n",
    "\n",
    "You are Deen Buddy â€” a kind and knowledgeable Islamic companion. Use wisdom and gentle speech.\n",
    "\n",
    "If you can answer from Qur'an or Hadith, do so with references. If not, admit respectfully.\n",
    "\n",
    "Here is some reference context:\n",
    "{formatted_context}\n",
    "\n",
    "Respond naturally, without listing â€” just a warm, conversational reply.\n",
    "\"\"\"\n",
    "\n",
    "        # Call LLM\n",
    "        response = llm.invoke([HumanMessage(content=prompt)])\n",
    "        return response.content.strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"âš ï¸ Error: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26010a64-48e3-4df0-8178-766636857316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask something:  can you please make me understand the tafsir of verse 3 of surah baqarah?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¬ Response from Deen Buddy:\n",
      "\n",
      "**Explanation of SÅ«rah Al-Baqarah (2:2):**\n",
      "\n",
      "**Arabic:**  \n",
      "Ø°ÙÙ°Ù„ÙÙƒÙ Ø§Ù„Ù’ÙƒÙØªÙØ§Ø¨Ù Ù„ÙØ§ Ø±ÙÙŠÙ’Ø¨Ù Û› ÙÙÙŠÙ‡Ù Û› Ù‡ÙØ¯Ù‹Ù‰ Ù„ÙÙ‘Ù„Ù’Ù…ÙØªÙÙ‘Ù‚ÙÙŠÙ†Ù  \n",
      "\n",
      "**Translation:**  \n",
      "\"This is the Book about which there is no doubtâ€”a guidance for those conscious of Allah.\"  \n",
      "\n",
      "---\n",
      "\n",
      "This profound verse opens the Qurâ€™Änâ€™s second chapter by affirming the divine authenticity of the Book and its purpose as an unwavering source of light. Let us reflect on its layers of meaning:  \n",
      "\n",
      "1. **\"This is the Book about which there is no doubt\"**  \n",
      "   The phrase *\"Ù„ÙØ§ Ø±ÙÙŠÙ’Ø¨Ù\"* (no doubt) eliminates any ambiguity about the Qurâ€™Änâ€™s origin, truth, or perfection. It is a definitive statement from Allah, transcending human speculation. Scholars like Ibn Kathir emphasize that the Qurâ€™Änâ€™s clarity, consistency, and miraculous nature dispel uncertainty. It is a covenant from the Most Merciful, inviting hearts to submit with certainty.  \n",
      "\n",
      "2. **\"A guidance for the muttaqÄ«n\"**  \n",
      "   The *muttaqÄ«n* (those conscious of Allah) are those who guard against heedlessness, purify their intentions, and align their lives with divine principles. The Qurâ€™Änâ€™s guidance is not generic; it resonates deeply with those who *choose* to listen. As Al-Qurá¹­ubÄ« explains, *taqwÄ* (God-consciousness) is the key to unlocking this guidance. Like rain that revives fertile land, the Qurâ€™Än nourishes hearts already inclined toward sincerity and humility.  \n",
      "\n",
      "3. **The Spiritual Connection**  \n",
      "   This verse ties to the dua: *\"O Allah, I ask You for mercy from You that guides my heart...\"* The Qurâ€™Än is the ultimate manifestation of Allahâ€™s mercyâ€”a roadmap for the soul. Its verses heal confusion, mend brokenness, and ignite hope, as echoed in Surah Yusuf (12:87): *\"Do not lose hope in the mercy of Allah.\"* The guidance of the Book is not merely intellectual; it steers the heart toward peace and the limbs toward righteousness.  \n",
      "\n",
      "4. **Practical Relevance**  \n",
      "   Just as the rituals of Hajj and Umrah require *ihrÄm* (sacred state) and intention, engaging with the Qurâ€™Än demands spiritual readiness. To internalize its guidance, one must approach it with the purity of a seekerâ€”trusting, patient, and open. The dua *\"O Allah, be my Companion in loneliness...\"* reflects the human need for divine companionship, which the Qurâ€™Än fulfills by anchoring believers in Allahâ€™s eternal words.  \n",
      "\n",
      "In essence, this Äyah is both a declaration and an invitation. It assures us that the Qurâ€™Än is truth, and it calls us to cultivate *taqwÄ*â€”awakening our hearts to receive its light. Let it remind us that guidance is not lost to those who sincerely seek it, and Allahâ€™s mercy is ever near.  \n",
      "\n",
      "May we be among those who listen, reflect, and allow this Book to transform our souls. ğŸ¤²âœ¨\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Ask something: \")\n",
    "response = deen_buddy(query)\n",
    "print(\"\\nğŸ’¬ Response from Deen Buddy:\\n\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573d3f04-3a0f-4ed0-871e-436983c11397",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (your_env_name)",
   "language": "python",
   "name": "your_env_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
